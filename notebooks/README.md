# EVIL: Exploiting Software via Natural Language

## Notebooks (Coming Soon)

This folder contains a Google Colab notebook that you can run on a GPU runtime instance to run our finetuned best performing models (CodeBERT) on both the encoder and decoder datasets.


## TODO
- [x] Add in preprocessing options for both encoder and decoder datasets in the ``preproc`` folder
- [x] Edit `Launch.sh` to account for dataset and preprocessing selections
- [x] Edit `eval_prep.py` to account for dataset selection.
- [x] Update the README
- [x] CodeBERT download and set up
- [x] Dataset loading and preprocessing shell script written
- [x] Environment set up
- [ ] Upload finetuned models to Huggingface
- [ ] Write a Google Colab notebook to demo Python encoder generation and assembly decoder generation
- [ ] Implement encoder and decoder datasets in Huggingface
- [ ] Make a demo space on HuggingFace






 
